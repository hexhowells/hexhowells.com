<!doctype html>

<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Reading List</title>
  <meta name="description" content="Reading List">
  <meta name="author" content="SitePoint">

  <meta property="og:title" content="Reading List">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://www.blog.hexhowells.com/">
  <meta property="og:description" content="Reading List">

  <link rel="stylesheet" href="../../styles.css?v=1.0">

</head>

<body>
  <div class="blog-header">
    <div class="title">
      <h2><a href="https://hexhowells.com">HexHowells</a></h2>
    </div>
  </div>
  <div class="content">
    <h1>April</h1>

    <h2>Papers</h2>
    <ul class="big-list">
      <li>
        <a href="https://arxiv.org/abs/2403.17297v1">
          InternLM2 Technical Report
        </a>
      </li>
      
      <li>
        <a href="https://arxiv.org/abs/2307.08197v1">
          Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs
        </a>
      </li>

      <li>
        <a href="https://arxiv.org/abs/1904.05862">
          wav2vec: Unsupervised Pre-training for Speech Recognition
        </a>
      </li>
    </ul>

    <h2>Links</h2>
    <ul class="big-list">
      <li>
        <a href="https://arxiv.org/abs/2312.06681" target="_blank" rel="noopener noreferrer">
         https://arxiv.org/abs/2312.06681
        </a>
        Steering Llama 2 via Contrastive Activation Addition
      </li>

      <li>
        <a href="https://www.connectedpapers.com/" target="_blank" rel="noopener noreferrer">
         https://www.connectedpapers.com/
        </a>
        Explore connected papers in a visual graph
      </li>

      <li>
        <a href="https://people.idsia.ch/~juergen/who-invented-backpropagation.html" target="_blank" rel="noopener noreferrer">
         https://people.idsia.ch/~juergen/who-invented-backpropagation.html
        </a>
        Who Invented Backpropagation?
      </li>

      <li>
        <a href="https://til.simonwillison.net/llms/embed-paragraphs" target="_blank" rel="noopener noreferrer">
         https://til.simonwillison.net/llms/embed-paragraphs
        </a>
        Embedding paragraphs from my blog with E5-large-v2
      </li>

      <li>
        <a href="https://mini-gemini.github.io/" target="_blank" rel="noopener noreferrer">
         https://mini-gemini.github.io/
        </a>
        Mini-Gemini - Mining the Potential of Multi-modality Vision Language Models
      </li>

      <li>
        <a href="https://cma-es.github.io/" target="_blank" rel="noopener noreferrer">
         https://cma-es.github.io/
        </a>
        The CMA Evolution Strategy
      </li>

      <li>
        <a href="https://github.com/vasturiano/3d-force-graph" target="_blank" rel="noopener noreferrer">
         https://github.com/vasturiano/3d-force-graph
        </a>
        3D Force-Directed Graph
      </li>

      <li>
        <a href="https://pytorch-geometric.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">
         https://pytorch-geometric.readthedocs.io/en/latest/
        </a>
        PyG Documentation (PyTorch Geometric) - Train Graph Neural Networks (GNNs)
      </li>

      <li>
        <a href="https://www.neuronpedia.org/" target="_blank" rel="noopener noreferrer">
         https://www.neuronpedia.org/
        </a>
        Neuronpedia is an open platform for interpretability research
      </li>

      <li>
        <a href="https://www.openphilanthropy.org/research/reasoning-transparency/" target="_blank" rel="noopener noreferrer">
         https://www.openphilanthropy.org/research/reasoning-transparency/
        </a>
        Reasoning Transparency
      </li>

      <li>
        <a href="https://medium.com/@syoya/what-happens-in-sparse-autencoder-b9a5a69da5c6" target="_blank" rel="noopener noreferrer">
         https://medium.com/@syoya/what-happens-in-sparse-autencoder-b9a5a69da5c6
        </a>
        What happens in Sparse Autoencoder
      </li>

      <li>
        <a href="https://www.alignmentforum.org/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream" target="_blank" rel="noopener noreferrer">
         https://www.alignmentforum.org/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream
        </a>
        Open Source Sparse Autoencoders for all Residual Stream Layers of GPT2-Small
      </li>

      <li>
        <a href="https://jonathanbgn.com/2021/09/30/illustrated-wav2vec-2.html" target="_blank" rel="noopener noreferrer">
         https://jonathanbgn.com/2021/09/30/illustrated-wav2vec-2.html
        </a>
        An Illustrated Tour of Wav2vec 2.0
      </li>

      <li>
        <a href="https://cameronrwolfe.substack.com/p/llama-2-from-the-ground-up" target="_blank" rel="noopener noreferrer">
         https://cameronrwolfe.substack.com/p/llama-2-from-the-ground-up
        </a>
        LLaMA-2 from the Ground Up
      </li>

      <li>
        <a href="https://lightning.ai/blog/gradient-accumulation/" target="_blank" rel="noopener noreferrer">
         https://lightning.ai/blog/gradient-accumulation/
        </a>
        Finetuning LLMs on a Single GPU Using Gradient Accumulation
      </li>

      <li>
        <a href="https://medium.com/@anuj_shah/through-the-eyes-of-gabor-filter-17d1fdb3ac97" target="_blank" rel="noopener noreferrer">
         https://medium.com/@anuj_shah/through-the-eyes-of-gabor-filter-17d1fdb3ac97
        </a>
        Through The Eyes of Gabor Filter
      </li>

      <li>
        <a href="https://remyhax.xyz/posts/bggp4-quantum-rat/" target="_blank" rel="noopener noreferrer">
         https://remyhax.xyz/posts/bggp4-quantum-rat/
        </a>
        BGGP4: PleaseMom, QUANTUM, Rat?
      </li>

      <li>
        <a href="https://incidentdatabase.ai/" target="_blank" rel="noopener noreferrer">
         https://incidentdatabase.ai/
        </a>
        AI Incident Database
      </li>

      <li>
        <a href="https://towardsdatascience.com/why-and-how-to-achieve-longer-context-windows-for-llms-5f76f8656ea9" target="_blank" rel="noopener noreferrer">
         https://towardsdatascience.com/why-and-how-to-achieve-longer-context-windows-for-llms-5f76f8656ea9
        </a>
        Why and How to Achieve Longer Context Windows for LLMs
      </li>

      <li>
        <a href="https://rome.baulab.info/" target="_blank" rel="noopener noreferrer">
         https://rome.baulab.info/
        </a>
        Locating and Editing Factual Associations in GPT
      </li>

      <li>
        <a href="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens" target="_blank" rel="noopener noreferrer">
         https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens
        </a>
        Interpreting GPT: the logit lens
      </li>

      <li>
        <a href="https://www.neelnanda.io/mosaic" target="_blank" rel="noopener noreferrer">
         https://www.neelnanda.io/mosaic
        </a>
        Induction Mosaic
      </li>

      <li>
        <a href="https://www.alignmentforum.org/posts/bBuBDJBYHt39Q5zZy/decision-transformer-interpretability#Attention_and_Head_Ablation" target="_blank" rel="noopener noreferrer">
         https://www.alignmentforum.org/posts/bBuBDJBYHt39Q5zZy/decision-transformer-interpretability#Attention_and_Head_Ablation
        </a>
        Decision Transformer Interpretability
      </li>

      <li>
        <a href="https://towardsdatascience.com/how-to-interpret-gpt2-small-76e0536a588a" target="_blank" rel="noopener noreferrer">
         https://towardsdatascience.com/how-to-interpret-gpt2-small-76e0536a588a
        </a>
        How to Interpret GPT2-Small
      </li>

      <li>
        <a href="https://neelnanda-io.github.io/TransformerLens/" target="_blank" rel="noopener noreferrer">
         https://neelnanda-io.github.io/TransformerLens/
        </a>
        Transformer Lens
      </li>

      <li>
        <a href="https://www.neelnanda.io/mechanistic-interpretability/glossary" target="_blank" rel="noopener noreferrer">
         https://www.neelnanda.io/mechanistic-interpretability/glossary
        </a>
        A Comprehensive Mechanistic Interpretability Explainer & Glossary
      </li>

      <li>
        <a href="https://www.lesswrong.com/posts/TvrfY4c9eaGLeyDkE/induction-heads-illustrated" target="_blank" rel="noopener noreferrer">
         https://www.lesswrong.com/posts/TvrfY4c9eaGLeyDkE/induction-heads-illustrated
        </a>
        Induction heads - illustrated
      </li>

      <li>
        <a href="https://substack.recursal.ai/cp/143397465" target="_blank" rel="noopener noreferrer">
         https://substack.recursal.ai/cp/143397465
        </a>
        Dear VCâ€™s, please stop throwing money at AI founders with no commercial plan, besides AGI
      </li>

      <li>
        <a href="https://udlbook.github.io/udlbook/" target="_blank" rel="noopener noreferrer">
         https://udlbook.github.io/udlbook/
        </a>
        Understanding Deep Learning (book)
      </li>

      <li>
        <a href="https://www.math.ias.edu/avi/book" target="_blank" rel="noopener noreferrer">
         https://www.math.ias.edu/avi/book
        </a>
        Mathematics and Computation (book)
      </li>

      <li>
        <a href="https://clemenswinter.com/2024/04/07/the-simple-beauty-of-xor-floating-point-compression/" target="_blank" rel="noopener noreferrer">
         https://clemenswinter.com/2024/04/07/the-simple-beauty-of-xor-floating-point-compression/
        </a>
        The Simple Beauty of XOR Floating Point Compression
      </li>

      <li>
        <a href="https://paulbupejr.com/developing-the-optigap-sensor-system/" target="_blank" rel="noopener noreferrer">
         https://paulbupejr.com/developing-the-optigap-sensor-system/
        </a>
        R&D Case Study: Developing the OptiGap Sensor System
      </li>

      <li>
        <a href="https://eprint.iacr.org/2024/555" target="_blank" rel="noopener noreferrer">
         https://eprint.iacr.org/2024/555
        </a>
        Quantum Algorithms for Lattice Problems
      </li>

      <li>
        <a href="https://www.lesswrong.com/tag/orthogonality-thesis" target="_blank" rel="noopener noreferrer">
         https://www.lesswrong.com/tag/orthogonality-thesis
        </a>
        Orthogonality Thesis
      </li>

      <li>
        <a href="https://en.wikipedia.org/wiki/Unconventional_computing" target="_blank" rel="noopener noreferrer">
         https://en.wikipedia.org/wiki/Unconventional_computing
        </a>
        Unconventional computing
      </li>

      <li>
        <a href="https://web.archive.org/web/20120805130100/singularity.org/files/GISAI.html" target="_blank" rel="noopener noreferrer">
         https://web.archive.org/web/20120805130100/singularity.org/files/GISAI.html
        </a>
        General Intelligence and Seed AI 2.3
      </li>

      <li>
        <a href="https://time.is/Anywhere_on_Earth" target="_blank" rel="noopener noreferrer">
         https://time.is/Anywhere_on_Earth
        </a>
        Time Anywhere on Earth
      </li>

      <li>
        <a href="https://arena3-chapter1-transformer-interp.streamlit.app/" target="_blank" rel="noopener noreferrer">
         https://arena3-chapter1-transformer-interp.streamlit.app/
        </a>
        Chapter 1: Transformer Interpretability
      </li>

      <li>
        <a href="https://transformer-circuits.pub/2023/interpretability-dreams/index.html" target="_blank" rel="noopener noreferrer">
         https://transformer-circuits.pub/2023/interpretability-dreams/index.html
        </a>
        Interpretability Dreams
      </li>

      <li>
        <a href="https://10print.org/" target="_blank" rel="noopener noreferrer">
         https://10print.org/
        </a>
        10 PRINT CHR$(205.5+RND(1)); : GOTO 10
      </li>
    </ul>
  </div>
  </div>
</body>
</html>